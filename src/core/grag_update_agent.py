"""
GRAGÊõ¥Êñ∞Êô∫ËÉΩAgent
‰ΩøÁî®LLMÊù•Êô∫ËÉΩÂàÜÊûêÂØπËØùÂπ∂ÁîüÊàêÁ≤æÁ°ÆÁöÑÁü•ËØÜÂõæË∞±Êõ¥Êñ∞Êåá‰ª§
"""

import json
from typing import Dict, Any, List, Optional
from loguru import logger
from datetime import datetime

from src.core.llm_client import LLMClient
from src.graph.knowledge_graph import KnowledgeGraph


class GRAGUpdateAgent:
    """
    Âü∫‰∫éLLMÁöÑÁü•ËØÜÂõæË∞±Êõ¥Êñ∞Êô∫ËÉΩAgent
    ÂàÜÊûêÁî®Êà∑ËæìÂÖ•ÂíåAIÂõûÂ§çÔºåÁîüÊàêÁ≤æÁ°ÆÁöÑÂõæË∞±Êõ¥Êñ∞Êìç‰Ωú
    """
    
    def __init__(self, llm_client: LLMClient):
        self.llm_client = llm_client
        
    def analyze_conversation_for_updates(
        self, 
        user_input: str, 
        llm_response: str, 
        current_graph: KnowledgeGraph,
        recent_context: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ÂàÜÊûêÂØπËØùÂÜÖÂÆπÔºåÁîüÊàêÁü•ËØÜÂõæË∞±Êõ¥Êñ∞Êåá‰ª§
        
        Args:
            user_input: Áî®Êà∑ËæìÂÖ•
            llm_response: LLMÂõûÂ§ç
            current_graph: ÂΩìÂâçÁü•ËØÜÂõæË∞±Áä∂ÊÄÅ
            recent_context: ÊúÄËøëÁöÑÂØπËØù‰∏ä‰∏ãÊñá
            
        Returns:
            ÁªìÊûÑÂåñÁöÑÊõ¥Êñ∞Êåá‰ª§
        """
        try:
            # 1. Ëé∑ÂèñÁõ∏ÂÖ≥ÁöÑÂõæË∞±‰∏ä‰∏ãÊñá
            relevant_context = self._extract_relevant_graph_context(
                user_input, llm_response, current_graph
            )
            
            # 2. ÊûÑÂª∫ÂàÜÊûêPrompt
            analysis_prompt = self._build_analysis_prompt(
                user_input, llm_response, relevant_context, recent_context
            )
            
            # 3. ËØ∑Ê±ÇLLMËøõË°åÂàÜÊûêÔºàËÆ∞ÂΩïprompt‰∏éÂìçÂ∫îÈ¢ÑËßàÔºâ
            logger.info("üß† [GRAG] ËØ∑Ê±ÇLLMËøõË°åÊõ¥Êñ∞ÂàÜÊûê...")
            try:
                logger.info(f"[GRAG] Prompt preview (first 600 chars):\n---\n{analysis_prompt[:600]}\n---")
                logger.debug(f"[GRAG] Full analysis prompt:\n{analysis_prompt}")
            except Exception:
                pass

            analysis_result = self.llm_client.generate_response(
                analysis_prompt,
                max_tokens=2000,
                temperature=0.1,  # ‰ΩéÊ∏©Â∫¶Á°Æ‰øù‰∏ÄËá¥ÊÄß
                system_message="‰Ω†ÊòØ‰∏Ä‰∏™‰∏ìÈó®ÂàÜÊûêRPGÂØπËØùÂπ∂ÁîüÊàêÁü•ËØÜÂõæË∞±Êõ¥Êñ∞Êåá‰ª§ÁöÑÊô∫ËÉΩAgent„ÄÇËØ∑‰∏•Ê†ºÊåâÁÖßJSONÊ†ºÂºèËøîÂõûÂàÜÊûêÁªìÊûú„ÄÇ"
            )

            try:
                logger.info(f"[GRAG] LLM response preview (first 800 chars):\n---\n{(analysis_result or '')[:800]}\n---")
            except Exception:
                pass

            # 4. Ëß£ÊûêLLMËøîÂõûÁöÑÊõ¥Êñ∞Êåá‰ª§
            update_instructions = self._parse_llm_analysis(analysis_result)
            
            logger.info(f"GRAGÂàÜÊûêÂÆåÊàê: {len(update_instructions.get('operations', []))} ‰∏™Êìç‰Ωú")
            return update_instructions
            
        except Exception as e:
            logger.error(f"GRAGÊõ¥Êñ∞ÂàÜÊûêÂ§±Ë¥•: {e}")
            return {"operations": [], "error": str(e)}
    
    def _extract_relevant_graph_context(
        self, 
        user_input: str, 
        llm_response: str, 
        current_graph: KnowledgeGraph
    ) -> Dict[str, Any]:
        """
        ‰ªéÂΩìÂâçÂõæË∞±‰∏≠ÊèêÂèñ‰∏éÂØπËØùÁõ∏ÂÖ≥ÁöÑ‰∏ä‰∏ãÊñá
        """
        # ‰ΩøÁî®ÁÆÄÂçïÁöÑÂÖ≥ÈîÆËØçÂåπÈÖçÊâæÂà∞Áõ∏ÂÖ≥ÂÆû‰Ωì
        # Âú®ÂÆûÈôÖÁîü‰∫ß‰∏≠ÔºåËøôÈáåÂèØ‰ª•‰ΩøÁî®Êõ¥È´òÁ∫ßÁöÑÂÆû‰ΩìËØÜÂà´
        combined_text = f"{user_input} {llm_response}".lower()
        
        relevant_nodes = {}
        relevant_edges = []
        
        # ÈÅçÂéÜÂõæ‰∏≠ÁöÑÊâÄÊúâËäÇÁÇπÔºåÊâæÂà∞ÂèØËÉΩÁõ∏ÂÖ≥ÁöÑ
        for node_id, node_data in current_graph.graph.nodes(data=True):
            node_name = node_data.get('name', node_id).lower()
            if node_name in combined_text or node_id.lower() in combined_text:
                relevant_nodes[node_id] = node_data
                
                # Ëé∑ÂèñÁõ∏ÂÖ≥ÁöÑËæπ
                for src, tgt, edge_data in current_graph.graph.edges(data=True):
                    if src == node_id or tgt == node_id:
                        relevant_edges.append({
                            "source": src,
                            "target": tgt, 
                            "relationship": edge_data.get("relationship", "unknown"),
                            "data": edge_data
                        })
        
        return {
            "nodes": relevant_nodes,
            "edges": relevant_edges,
            "total_nodes": len(current_graph.graph.nodes()),
            "total_edges": len(current_graph.graph.edges())
        }
    
    def _build_analysis_prompt(
        self, 
        user_input: str, 
        llm_response: str, 
        relevant_context: Dict[str, Any],
        recent_context: Optional[str] = None
    ) -> str:
        """
        ÊûÑÂª∫Áî®‰∫éLLMÂàÜÊûêÁöÑPrompt
        """
        current_nodes_desc = ""
        if relevant_context["nodes"]:
            current_nodes_desc = "ÂΩìÂâçÁõ∏ÂÖ≥ËäÇÁÇπ:\n"
            for node_id, node_data in relevant_context["nodes"].items():
                current_nodes_desc += f"- {node_id}: {node_data}\n"
        
        current_edges_desc = ""
        if relevant_context["edges"]:
            current_edges_desc = "ÂΩìÂâçÁõ∏ÂÖ≥ÂÖ≥Á≥ª:\n"
            for edge in relevant_context["edges"][:10]:  # ÈôêÂà∂ÊòæÁ§∫Êï∞Èáè
                current_edges_desc += f"- {edge['source']} --{edge['relationship']}--> {edge['target']}\n"
        
        context_section = ""
        if recent_context:
            context_section = f"\nÊúÄËøëÂØπËØù‰∏ä‰∏ãÊñá:\n{recent_context}\n"
        
        prompt = f"""‰Ω†ÊòØ‰∏Ä‰∏™RPGÁü•ËØÜÂõæË∞±ÁÆ°ÁêÜ‰∏ìÂÆ∂„ÄÇËØ∑ÂàÜÊûê‰ª•‰∏ãÂØπËØùÔºåÁ°ÆÂÆöÈúÄË¶ÅÂØπÁü•ËØÜÂõæË∞±ËøõË°åÁöÑÊõ¥Êñ∞Êìç‰Ωú„ÄÇ

{context_section}
Áî®Êà∑ËæìÂÖ•: {user_input}
AIÂõûÂ§ç: {llm_response}

ÂΩìÂâçÁü•ËØÜÂõæË∞±Áä∂ÊÄÅ:
{current_nodes_desc}
{current_edges_desc}

ËØ∑‰ªîÁªÜÂàÜÊûêÂØπËØùÂÜÖÂÆπÔºåÁ°ÆÂÆöÈúÄË¶ÅÊâßË°åÁöÑÊìç‰Ωú„ÄÇËÄÉËôë‰ª•‰∏ãÊñπÈù¢:
1. Êñ∞Âá∫Áé∞ÁöÑÂÆû‰ΩìÔºàËßíËâ≤„ÄÅÁâ©ÂìÅ„ÄÅÂú∞ÁÇπ„ÄÅÁªÑÁªáÁ≠âÔºâ
2. ÂÆû‰ΩìÂ±ûÊÄßÁöÑÂèòÂåñÔºàË°ÄÈáè„ÄÅÁ≠âÁ∫ß„ÄÅÁä∂ÊÄÅ„ÄÅ‰ΩçÁΩÆÁ≠âÔºâ
3. ÂÆû‰ΩìÈó¥ÂÖ≥Á≥ªÁöÑÂèòÂåñÔºàË£ÖÂ§á„ÄÅ‰ΩçÁΩÆ„ÄÅÊïåÂØπ„ÄÅÂèãÂ•ΩÁ≠âÔºâ
4. ÂÆû‰ΩìÁöÑÊ∂àÂ§±ÊàñÂà†Èô§ÔºàÊ≠ª‰∫°„ÄÅ‰∏¢Â§±„ÄÅÁ¶ªÂºÄÁ≠âÔºâ
5. ÊäÄËÉΩÂ≠¶‰π†„ÄÅÁä∂ÊÄÅËé∑ÂæóÁ≠â‰∫ã‰ª∂

ËØ∑‰∏•Ê†ºÊåâÁÖß‰ª•‰∏ãJSONÊ†ºÂºèËøîÂõûÂàÜÊûêÁªìÊûú:

{{
    "analysis_summary": "ÂØπËØùÂàÜÊûêÊÄªÁªì",
    "operations": [
        {{
            "type": "add_node",
            "node_id": "ÂÆû‰ΩìÂîØ‰∏ÄID",
            "node_type": "ÂÆû‰ΩìÁ±ªÂûã(character/item/location/skill/organization/event)",
            "attributes": {{
                "name": "ÂÆû‰ΩìÂêçÁß∞",
                "ÂÖ∂‰ªñÂ±ûÊÄß": "ÂÄº"
            }},
            "reason": "Ê∑ªÂä†Ê≠§ËäÇÁÇπÁöÑÂéüÂõ†"
        }},
        {{
            "type": "update_node",
            "node_id": "Áé∞ÊúâËäÇÁÇπID",
            "attributes": {{
                "Â±ûÊÄßÂêç": "Êñ∞ÂÄº"
            }},
            "reason": "Êõ¥Êñ∞ÂéüÂõ†"
        }},
        {{
            "type": "add_edge",
            "source": "Ê∫êËäÇÁÇπID",
            "target": "ÁõÆÊ†áËäÇÁÇπID", 
            "relationship": "ÂÖ≥Á≥ªÁ±ªÂûã",
            "attributes": {{}},
            "reason": "Ê∑ªÂä†ÂÖ≥Á≥ªÁöÑÂéüÂõ†"
        }},
        {{
            "type": "delete_node",
            "node_id": "Ë¶ÅÂà†Èô§ÁöÑËäÇÁÇπID",
            "deletion_type": "death/lost/destroyed/other",
            "reason": "Âà†Èô§ÂéüÂõ†"
        }},
        {{
            "type": "delete_edge",
            "source": "Ê∫êËäÇÁÇπID",
            "target": "ÁõÆÊ†áËäÇÁÇπID",
            "relationship": "Ë¶ÅÂà†Èô§ÁöÑÂÖ≥Á≥ªÁ±ªÂûã",
            "reason": "Âà†Èô§ÂÖ≥Á≥ªÁöÑÂéüÂõ†"
        }}
    ],
    "confidence": "ÂàÜÊûêÁΩÆ‰ø°Â∫¶(0-1)",
    "notes": "È¢ùÂ§ñËØ¥ÊòéÊàñ‰∏çÁ°ÆÂÆöÁöÑÂú∞Êñπ"
}}

ÈáçË¶ÅÊèêÈÜí:
- Âè™ÊúâÂú®ÂØπËØù‰∏≠ÊòéÁ°ÆÊèêÂà∞ÂèòÂåñÊó∂ÊâçÁîüÊàêÊìç‰Ωú
- ‰∏çË¶ÅÈáçÂ§çÂàõÂª∫Â∑≤Â≠òÂú®ÁöÑËäÇÁÇπÊàñÂÖ≥Á≥ª
- ÂØπ‰∫éÊ®°Á≥äÊàñ‰∏çÁ°ÆÂÆöÁöÑ‰ø°ÊÅØÔºåÈôç‰ΩéÁΩÆ‰ø°Â∫¶
- ‰øùÊåÅËäÇÁÇπIDÁöÑ‰∏ÄËá¥ÊÄßÂíåÂèØËØªÊÄß
- ‰ºòÂÖàËÄÉËôëÊòæÂºè‰ø°ÊÅØÔºåË∞®ÊÖéÊé®Êñ≠ÈöêÂê´‰ø°ÊÅØ"""

        return prompt
    
    def _parse_llm_analysis(self, analysis_result: str) -> Dict[str, Any]:
        """
        Ëß£ÊûêLLMËøîÂõûÁöÑÂàÜÊûêÁªìÊûú
        """
        try:
            # Â∞ùËØïÊèêÂèñJSONÈÉ®ÂàÜ
            analysis_result = analysis_result.strip()
            
            # Â¶ÇÊûúÂåÖÂê´‰ª£Á†ÅÂùóÔºåÊèêÂèñJSON
            if "```json" in analysis_result:
                start = analysis_result.find("```json") + 7
                end = analysis_result.find("```", start)
                json_str = analysis_result[start:end].strip()
            elif "```" in analysis_result:
                start = analysis_result.find("```") + 3
                end = analysis_result.rfind("```")
                json_str = analysis_result[start:end].strip()
            else:
                json_str = analysis_result
            
            # Ëß£ÊûêJSON
            parsed_result = json.loads(json_str)
            
            # È™åËØÅÂøÖË¶ÅÂ≠óÊÆµ
            if "operations" not in parsed_result:
                parsed_result["operations"] = []
            
            # È™åËØÅÊØè‰∏™Êìç‰ΩúÁöÑÊ†ºÂºè
            validated_operations = []
            for op in parsed_result["operations"]:
                if self._validate_operation(op):
                    validated_operations.append(op)
                else:
                    logger.warning(f"Ë∑≥ËøáÊó†ÊïàÊìç‰Ωú: {op}")
            
            parsed_result["operations"] = validated_operations
            return parsed_result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSONËß£ÊûêÂ§±Ë¥•: {e}")
            logger.debug(f"ÂéüÂßãÂìçÂ∫î: {analysis_result}")
            return {
                "operations": [],
                "error": "JSONÊ†ºÂºèËß£ÊûêÂ§±Ë¥•",
                "raw_response": analysis_result
            }
        except Exception as e:
            logger.error(f"ÂàÜÊûêÁªìÊûúËß£ÊûêÂ§±Ë¥•: {e}")
            return {
                "operations": [],
                "error": str(e),
                "raw_response": analysis_result
            }
    
    def _validate_operation(self, operation: Dict[str, Any]) -> bool:
        """
        È™åËØÅÊìç‰ΩúÊ†ºÂºèÊòØÂê¶Ê≠£Á°Æ
        """
        if not isinstance(operation, dict):
            return False
        
        op_type = operation.get("type")
        if op_type not in ["add_node", "update_node", "add_edge", "delete_node", "delete_edge"]:
            logger.warning(f"Êú™Áü•Êìç‰ΩúÁ±ªÂûã: {op_type}")
            return False
        
        # È™åËØÅÊØèÁßçÊìç‰ΩúÁöÑÂøÖÈúÄÂ≠óÊÆµ
        if op_type == "add_node":
            return all(key in operation for key in ["node_id", "node_type", "attributes"])
        elif op_type == "update_node":
            return all(key in operation for key in ["node_id", "attributes"])
        elif op_type == "add_edge":
            return all(key in operation for key in ["source", "target", "relationship"])
        elif op_type in ["delete_node", "delete_edge"]:
            return "reason" in operation
        
        return True
    
    def convert_to_execution_format(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        Â∞ÜAgentÂàÜÊûêÁªìÊûúËΩ¨Êç¢‰∏∫ÊâßË°åÊ†ºÂºè
        """
        nodes_to_add = []
        nodes_to_update = []
        edges_to_add = []
        nodes_to_delete = []
        edges_to_delete = []
        
        for operation in analysis_result.get("operations", []):
            op_type = operation["type"]
            
            if op_type == "add_node":
                nodes_to_add.append({
                    "node_id": operation["node_id"],
                    "type": operation["node_type"],
                    "attributes": operation["attributes"]
                })
            
            elif op_type == "update_node":
                nodes_to_update.append({
                    "node_id": operation["node_id"],
                    "attributes": operation["attributes"]
                })
            
            elif op_type == "add_edge":
                edges_to_add.append({
                    "source": operation["source"],
                    "target": operation["target"],
                    "relationship": operation["relationship"],
                    "attributes": operation.get("attributes", {})
                })
            
            elif op_type == "delete_node":
                nodes_to_delete.append({
                    "node_id": operation["node_id"],
                    "deletion_type": operation.get("deletion_type", "other"),
                    "reason": operation["reason"]
                })
            
            elif op_type == "delete_edge":
                edges_to_delete.append({
                    "source": operation["source"],
                    "target": operation["target"],
                    "relationship": operation.get("relationship"),
                    "reason": operation["reason"]
                })
        
        return {
            "nodes_to_add": nodes_to_add,
            "nodes_to_update": nodes_to_update,
            "edges_to_add": edges_to_add,
            "nodes_to_delete": nodes_to_delete,
            "edges_to_delete": edges_to_delete,
            "analysis_summary": analysis_result.get("analysis_summary", ""),
            "confidence": analysis_result.get("confidence", 0.5),
            "notes": analysis_result.get("notes", "")
        }