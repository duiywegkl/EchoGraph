import json
import re
from typing import Dict, Any, List, TYPE_CHECKING
from loguru import logger

from src.utils.config import config
from src.core.rpg_text_processor import RPGTextProcessor
from src.core.perception import PerceptionModule
from src.memory import GRAGMemory
from src.core.validation import ValidationLayer

if TYPE_CHECKING:
    from src.core.grag_update_agent import GRAGUpdateAgent

class GameEngine:
    """ChronoForge æ ¸å¿ƒæ¸¸æˆå¼•æ“Žï¼Œé€‚é… SillyTavern æ’ä»¶åŽç«¯"""
    
    def __init__(self, memory: GRAGMemory, perception: PerceptionModule, rpg_processor: RPGTextProcessor, validation_layer: ValidationLayer, grag_agent: 'GRAGUpdateAgent' = None):
        self.memory = memory
        self.perception = perception
        self.rpg_processor = rpg_processor
        self.validation_layer = validation_layer
        self.grag_agent = grag_agent
        logger.info(f"GameEngine åˆå§‹åŒ–å®Œæˆï¼Œ{'æ”¯æŒæ™ºèƒ½Agentåˆ†æž' if grag_agent else 'ä½¿ç”¨æœ¬åœ°æ–‡æœ¬å¤„ç†å™¨'}ã€‚")

    def initialize_from_tavern_data(self, character_card: Dict[str, Any], world_info: str):
        """
        ä½¿ç”¨LLMæ™ºèƒ½è§£æžè§’è‰²å¡å’Œä¸–ç•Œä¹¦ï¼Œç”ŸæˆçŸ¥è¯†å›¾è°±åˆå§‹åŒ–æ•°æ®ã€‚
        å¦‚æžœLLMä¸å¯ç”¨ï¼Œåˆ™è‡ªåŠ¨å›žé€€åˆ°ç®€åŒ–åˆå§‹åŒ–æ¨¡å¼ã€‚
        """
        logger.info("ðŸ§  å¼€å§‹åˆå§‹åŒ–è§’è‰²å¡å’Œä¸–ç•Œä¹¦...")

        try:
            # 1. å‡†å¤‡è§’è‰²å¡æ•°æ®
            char_name = character_card.get('name', 'Unknown Character')
            char_description = character_card.get('description', '')
            char_personality = character_card.get('personality', '')
            char_scenario = character_card.get('scenario', '')
            char_first_mes = character_card.get('first_mes', '')
            char_example = character_card.get('mes_example', '')
            
            logger.info(f"ðŸ“Š è§’è‰²ä¿¡æ¯: {char_name}")
            logger.info(f"ðŸ“Š æè¿°é•¿åº¦: {len(char_description)} å­—ç¬¦")
            logger.info(f"ðŸ“Š ä¸–ç•Œä¹¦é•¿åº¦: {len(world_info or '')} å­—ç¬¦")
            
            # 2. æ£€æŸ¥LLMæ˜¯å¦å¯ç”¨ä¸”æ­£ç¡®é…ç½®
            if not self._is_llm_available():
                logger.info("âš¡ LLMä¸å¯ç”¨ï¼Œç›´æŽ¥ä½¿ç”¨ç®€åŒ–åˆå§‹åŒ–")
                return self._fallback_simple_initialization(char_name, char_description)
            
            # 3. å°è¯•ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½è§£æž
            logger.info("ðŸ¤– å°è¯•ä½¿ç”¨LLMè¿›è¡Œè§’è‰²å¡è¯­ä¹‰åˆ†æž...")
            
            try:
                # ç›´æŽ¥å°è¯•LLMåˆ†æžï¼Œä¾èµ–LLMå®¢æˆ·ç«¯è‡ªå¸¦çš„è¶…æ—¶æœºåˆ¶
                analysis_result = self._perform_llm_analysis(
                    char_name, char_description, char_personality, 
                    char_scenario, char_first_mes, char_example, world_info
                )
                
                if analysis_result:
                    logger.info("âœ… LLMåˆ†æžæˆåŠŸå®Œæˆ")
                    return analysis_result
                else:
                    logger.warning("âš ï¸ LLMåˆ†æžè¿”å›žç©ºç»“æžœï¼Œä½¿ç”¨ç®€åŒ–åˆå§‹åŒ–")
                    return self._fallback_simple_initialization(char_name, char_description)
                    
            except Exception as llm_error:
                logger.warning(f"âš ï¸ LLMåˆ†æžå¤±è´¥: {llm_error}")
                logger.info("ðŸ”„ å›žé€€åˆ°ç®€åŒ–åˆå§‹åŒ–æ¨¡å¼...")
                return self._fallback_simple_initialization(char_name, char_description)
            
        except Exception as e:
            logger.error(f"âŒ è§’è‰²å¡åˆå§‹åŒ–è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return self._fallback_simple_initialization(char_name or "Unknown", "")
    
    def _is_llm_available(self) -> bool:
        """æ£€æŸ¥LLMæ˜¯å¦å¯ç”¨"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰gRAG Agent
            if not self.grag_agent:
                logger.info("ðŸ“ æ²¡æœ‰gRAG Agentï¼ŒLLMä¸å¯ç”¨")
                return False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰LLMå®¢æˆ·ç«¯
            if not hasattr(self.grag_agent, 'llm_client') or not self.grag_agent.llm_client:
                logger.info("ðŸ“ æ²¡æœ‰LLMå®¢æˆ·ç«¯ï¼ŒLLMä¸å¯ç”¨")
                return False
            
            # æ£€æŸ¥APIå¯†é’¥é…ç½®
            from src.utils.config import config
            if not config.llm.api_key:
                logger.info("ðŸ“ LLM APIå¯†é’¥æœªé…ç½®ï¼ŒLLMä¸å¯ç”¨")
                return False
            
            logger.info("âœ… LLMæ£€æŸ¥é€šè¿‡ï¼Œå¯ä»¥ä½¿ç”¨æ™ºèƒ½åˆ†æž")
            return True
            
        except Exception as e:
            logger.warning(f"âš ï¸ LLMå¯ç”¨æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def _perform_llm_analysis(self, name: str, description: str, personality: str, 
                             scenario: str, first_mes: str, example: str, world_info: str) -> Dict[str, Any]:
        """æ‰§è¡ŒLLMåˆ†æžï¼ˆå¸¦å¿«é€Ÿå¤±è´¥æœºåˆ¶ï¼‰"""
        import time
        try:
            # æž„å»ºåˆ†æžæç¤º
            analysis_prompt = self._build_character_analysis_prompt(
                name, description, personality, scenario, first_mes, example, world_info
            )
            
            # --- è¯¦ç»†æ—¥å¿— ---
            logger.info("="*50)
            logger.info("ðŸ“œ [LLM KG Gen] Preparing to call LLM for Knowledge Graph generation.")
            logger.info(f"è§’è‰²åç§°: {name}")
            logger.info(f"è§’è‰²æè¿°:\n---\n{description}\n---")
            logger.info(f"ä¸–ç•Œä¹¦:\n---\n{world_info}\n---")
            logger.info("Full prompt sent to LLM will be logged at DEBUG level.")
            logger.debug(f"Full LLM Prompt:\n{analysis_prompt}")
            logger.info("="*50)
            
            # è°ƒç”¨LLMå¹¶è®¡æ—¶
            start_time = time.time()
            analysis_result = self.grag_agent.llm_client.generate_response(
                prompt=analysis_prompt,
                system_message="ä½ æ˜¯ä¸€ä¸ªä¸“é—¨åˆ†æžè§’è‰²æ‰®æ¼”æ¸¸æˆè§’è‰²å¡çš„AIåŠ©æ‰‹ã€‚ä½ éœ€è¦ä»Žè§’è‰²æè¿°ä¸­æå–ç»“æž„åŒ–çš„å®žä½“å’Œå…³ç³»ä¿¡æ¯ï¼Œä»¥JSONæ ¼å¼è¿”å›žã€‚è¯·ç¡®ä¿JSONæ ¼å¼å®Œæ•´ï¼Œä¸è¦æˆªæ–­ã€‚",
                temperature=0.1,
                max_tokens=16000  # è¿›ä¸€æ­¥å¢žåŠ tokené™åˆ¶ï¼Œç¡®ä¿å®Œæ•´è¾“å‡º
            )
            end_time = time.time()
            
            # --- è¯¦ç»†æ—¥å¿— ---
            duration = end_time - start_time
            logger.info("="*50)
            logger.info(f"âœ… [LLM KG Gen] LLM call completed in {duration:.2f} seconds.")
            logger.info(f"LLM Raw Response:\n---\n{analysis_result}\n---")
            logger.info("="*50)
            
            # è§£æžç»“æžœ
            import json
            logger.info(f"[LLM KG Gen] å¼€å§‹è§£æžLLMè¿”å›žçš„JSONæ•°æ®...")
            parsed_data = json.loads(analysis_result)
            logger.info(f"[LLM KG Gen] JSONè§£æžæˆåŠŸ")
            logger.info(f"[LLM KG Gen] è§£æžç»“æžœç»Ÿè®¡: {len(parsed_data.get('entities', []))} ä¸ªå®žä½“, {len(parsed_data.get('relationships', []))} ä¸ªå…³ç³»")

            # è®°å½•ä¸»è§’è‰²ä¿¡æ¯
            main_char_data = parsed_data.get("main_character")
            if main_char_data:
                logger.info(f"[LLM KG Gen] ä¸»è§’è‰²: {main_char_data.get('name', 'Unknown')}")
            else:
                logger.warning(f"[LLM KG Gen] æœªæ‰¾åˆ°ä¸»è§’è‰²æ•°æ®")

            # è®°å½•å®žä½“ä¿¡æ¯
            entities = parsed_data.get("entities", [])
            logger.info(f"[LLM KG Gen] å®žä½“è¯¦æƒ…:")
            for i, entity in enumerate(entities[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
                logger.info(f"  {i+1}. {entity.get('name', 'Unknown')} ({entity.get('type', 'unknown')})")
            if len(entities) > 5:
                logger.info(f"  ... è¿˜æœ‰ {len(entities)-5} ä¸ªå®žä½“")

            # è®°å½•å…³ç³»ä¿¡æ¯
            relationships = parsed_data.get("relationships", [])
            logger.info(f"[LLM KG Gen] å…³ç³»è¯¦æƒ…:")
            for i, rel in enumerate(relationships[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                logger.info(f"  {i+1}. {rel.get('source', 'Unknown')} --{rel.get('relationship', 'unknown')}--> {rel.get('target', 'Unknown')}")
            if len(relationships) > 3:
                logger.info(f"  ... è¿˜æœ‰ {len(relationships)-3} ä¸ªå…³ç³»")
            
            # åº”ç”¨åˆ°çŸ¥è¯†å›¾è°±
            logger.info(f"[LLM KG Gen] å¼€å§‹å°†è§£æžç»“æžœåº”ç”¨åˆ°çŸ¥è¯†å›¾è°±...")
            nodes_added, edges_added = self._apply_llm_analysis_results(parsed_data, name)
            logger.info(f"[LLM KG Gen] çŸ¥è¯†å›¾è°±åº”ç”¨å®Œæˆ: æ·»åŠ äº†{nodes_added}ä¸ªèŠ‚ç‚¹, {edges_added}ä¸ªå…³ç³»")
            
            # ä¿å­˜çŸ¥è¯†å›¾è°±åˆ°GraphMLæ ¼å¼
            if self.memory.graph_save_path:
                self.memory.knowledge_graph.save_graph(self.memory.graph_save_path)

            # åŒæ­¥å®žä½“æ•°æ®åˆ°JSONæ–‡ä»¶ï¼Œä¾›UIä½¿ç”¨
            self.memory.sync_entities_to_json()
            logger.info("âœ… å®žä½“æ•°æ®å·²åŒæ­¥åˆ° entities.json")

            return {
                "nodes_added": nodes_added,
                "edges_added": edges_added,
                "method": "llm_analysis",
                "character_name": name
            }
            
        except json.JSONDecodeError as je:
            logger.error(f"âŒ LLMè¿”å›žçš„JSONè§£æžå¤±è´¥: {je}")
            logger.error(f"LLM Raw Response that caused error:\n---\n{analysis_result}\n---")
            return None
        except Exception as e:
            logger.error(f"âŒ LLMåˆ†æžæ‰§è¡Œå¤±è´¥: {e}")
            return None
    
    def _build_character_analysis_prompt(self, name: str, description: str, personality: str, 
                                       scenario: str, first_mes: str, example: str, world_info: str) -> str:
        """æž„å»ºè§’è‰²åˆ†æžçš„LLMæç¤ºè¯"""
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†å›¾è°±æž„å»ºåŠ©æ‰‹ï¼Œè¯·ä»”ç»†åˆ†æžä»¥ä¸‹è§’è‰²æ‰®æ¼”æ¸¸æˆè§’è‰²å¡ï¼Œæå–æ‰€æœ‰å®žä½“å’Œå…³ç³»ã€‚

ã€å…³é”®è¦æ±‚ã€‘ï¼šå¿…é¡»åˆ›å»ºå°½å¯èƒ½å¤šçš„å…³ç³»è¿žæŽ¥ï¼Œç¡®ä¿å®žä½“ä¹‹é—´å½¢æˆæœ‰æ„ä¹‰çš„çŸ¥è¯†ç½‘ç»œï¼

è§’è‰²ä¿¡æ¯ï¼š
è§’è‰²åç§°: {name}

è§’è‰²æè¿°:
{description}

æ€§æ ¼ç‰¹å¾:
{personality}

èƒŒæ™¯åœºæ™¯:
{scenario}

é¦–æ¬¡å¯¹è¯:
{first_mes}

å¯¹è¯ç¤ºä¾‹:
{example}

ä¸–ç•Œè®¾å®šä¿¡æ¯:
{world_info}

è¯·è¿”å›žå®Œæ•´çš„JSONç»“æž„ï¼ˆä¸è¦æˆªæ–­ï¼‰ï¼š
{{
    "main_character": {{
        "name": "è§’è‰²ä¸»åç§°",
        "type": "character",
        "attributes": {{
            "description": "è§’è‰²ç®€è¦æè¿°ï¼ˆä¸è¶…è¿‡200å­—ç¬¦ï¼‰",
            "personality_traits": ["æ€§æ ¼ç‰¹å¾1", "æ€§æ ¼ç‰¹å¾2"],
            "background": "èƒŒæ™¯ç®€è¿°",
            "is_main_character": true
        }}
    }},
    "entities": [
        {{
            "name": "å®žä½“åç§°",
            "type": "ç±»åž‹ï¼ˆcharacter/location/item/skill/organization/conceptç­‰ï¼‰",
            "description": "å®žä½“æè¿°",
            "attributes": {{
                "key": "value"
            }}
        }}
    ],
    "relationships": [
        {{
            "source": "æºå®žä½“åç§°ï¼ˆå¿…é¡»ä¸Žentitiesæˆ–main_characterä¸­çš„nameå®Œå…¨åŒ¹é…ï¼‰",
            "target": "ç›®æ ‡å®žä½“åç§°ï¼ˆå¿…é¡»ä¸Žentitiesæˆ–main_characterä¸­çš„nameå®Œå…¨åŒ¹é…ï¼‰",
            "relationship": "å…³ç³»ç±»åž‹ï¼ˆæœ‹å‹/æ•Œäºº/æ‹¥æœ‰/ä½äºŽ/å±žäºŽ/æŽŒæ¡/ç»Ÿæ²»/ä¿æŠ¤/æœåŠ¡ç­‰ï¼‰",
            "description": "å…³ç³»æè¿°"
        }}
    ]
}}

ã€é‡è¦è§„åˆ™ã€‘ï¼š
1. åç§°åŒ¹é…ï¼šrelationshipsä¸­çš„sourceå’Œtargetå¿…é¡»ä¸Žentitiesæˆ–main_characterä¸­çš„nameå®Œå…¨ä¸€è‡´
2. å…³ç³»å¯†åº¦ï¼šæ¯ä¸ªå®žä½“éƒ½åº”è¯¥è‡³å°‘è¿žæŽ¥åˆ°2-3ä¸ªå…¶ä»–å®žä½“
3. å…³ç³»ç±»åž‹ï¼šåŒ…æ‹¬ä½†ä¸é™äºŽï¼š
   - äººé™…å…³ç³»ï¼šæœ‹å‹ã€æ•Œäººã€åŒäº‹ã€å®¶äººã€å¸ˆç”Ÿã€æ‹äººã€ç«žäº‰å¯¹æ‰‹
   - ä½ç½®å…³ç³»ï¼šå±…ä½ã€å·¥ä½œã€è®¿é—®ã€ç»Ÿæ²»ã€å®ˆæŠ¤ã€ä½äºŽ
   - ç‰©å“å…³ç³»ï¼šæ‹¥æœ‰ã€ä½¿ç”¨ã€åˆ¶é€ ã€å¯»æ‰¾ã€ä¸¢å¤±
   - æŠ€èƒ½å…³ç³»ï¼šæŽŒæ¡ã€å­¦ä¹ ã€æ•™æŽˆã€ä¸“é•¿
   - ç»„ç»‡å…³ç³»ï¼šå±žäºŽã€ç®¡ç†ã€æœåŠ¡ã€å¯¹ç«‹
4. å¿…é¡»å®Œæ•´è¾“å‡ºï¼šä¸è¦å› ä¸ºé•¿åº¦é™åˆ¶è€Œæˆªæ–­JSONï¼Œç¡®ä¿å®Œæ•´çš„å³æ‹¬å·ç»“å°¾
5. å…³ç³»ä¼˜å…ˆï¼šå®å¯å°‘å‡ ä¸ªå®žä½“ï¼Œä¹Ÿè¦ç¡®ä¿å®žä½“é—´æœ‰å……åˆ†çš„å…³ç³»è¿žæŽ¥

å¼€å§‹åˆ†æžå¹¶è¾“å‡ºå®Œæ•´JSONï¼ˆç¡®ä¿ä»¥}}ç»“å°¾ï¼‰ï¼š
"""
        return prompt.strip()
    
    def _apply_llm_analysis_results(self, parsed_data: Dict[str, Any], char_name: str) -> tuple[int, int]:
        """å°†LLMè§£æžç»“æžœåº”ç”¨åˆ°çŸ¥è¯†å›¾è°±"""
        nodes_added = 0
        edges_added = 0

        logger.info(f"[Apply Results] å¼€å§‹åº”ç”¨LLMåˆ†æžç»“æžœåˆ°çŸ¥è¯†å›¾è°±")

        try:
            # 1. æ·»åŠ ä¸»è§’è‰²
            main_char_data = parsed_data.get("main_character")
            if main_char_data:
                char_id = self._generate_entity_id(main_char_data.get("name", char_name), "character")
                attributes = main_char_data.get("attributes", {})
                attributes.update({
                    "name": main_char_data.get("name", char_name),
                    "source": "llm_character_card",
                    "is_main_character": True
                })

                logger.info(f"[Apply Results] æ­£åœ¨æ·»åŠ ä¸»è§’è‰²: {main_char_data.get('name', char_name)} -> {char_id}")
                self.memory.add_or_update_node(char_id, "character", **attributes)
                nodes_added += 1
                logger.info(f"[Apply Results] ä¸»è§’è‰²æ·»åŠ æˆåŠŸ, å½“å‰ nodes_added = {nodes_added}")
            else:
                logger.warning(f"[Apply Results] æœªæ‰¾åˆ°ä¸»è§’è‰²æ•°æ®")

            # 2. æ·»åŠ å…¶ä»–å®žä½“
            entities = parsed_data.get("entities", [])
            logger.info(f"[Apply Results] å¼€å§‹æ·»åŠ  {len(entities)} ä¸ªå®žä½“...")
            for i, entity in enumerate(entities):
                if not entity.get("name"):
                    logger.warning(f"[Apply Results] å®žä½“{i+1}ç¼ºå°‘åç§°ï¼Œè·³è¿‡")
                    continue

                entity_id = self._generate_entity_id(entity["name"], entity.get("type", "unknown"))
                attributes = entity.get("attributes", {})
                attributes.update({
                    "name": entity["name"],
                    "description": entity.get("description", ""),
                    "source": "llm_analysis"
                })

                logger.info(f"[Apply Results] æ­£åœ¨æ·»åŠ å®žä½“{i+1}: {entity['name']} ({entity.get('type', 'unknown')}) -> {entity_id}")
                self.memory.add_or_update_node(entity_id, entity.get("type", "unknown"), **attributes)
                nodes_added += 1
                logger.info(f"[Apply Results] å®žä½“{i+1}æ·»åŠ æˆåŠŸ, å½“å‰ nodes_added = {nodes_added}")
            
            # 3. æ·»åŠ å…³ç³»
            relationships = parsed_data.get("relationships", [])
            logger.info(f"[Apply Results] å¼€å§‹æ·»åŠ  {len(relationships)} ä¸ªå…³ç³»...")

            # åˆ›å»ºä¸€ä¸ªå®žä½“åç§°åˆ°IDçš„æ˜ å°„ï¼Œç”¨äºŽå…³ç³»å»ºç«‹
            entity_name_to_id = {}

            # æ·»åŠ ä¸»è§’è‰²åˆ°æ˜ å°„
            if main_char_data:
                char_name_final = main_char_data.get("name", char_name)
                char_id = self._generate_entity_id(char_name_final, "character")
                entity_name_to_id[char_name_final] = char_id
                logger.info(f"[Apply Results] ä¸»è§’è‰²æ˜ å°„: '{char_name_final}' -> '{char_id}'")

            # æ·»åŠ æ‰€æœ‰å®žä½“åˆ°æ˜ å°„
            entities = parsed_data.get("entities", [])
            for entity in entities:
                if entity.get("name"):
                    entity_id = self._generate_entity_id(entity["name"], entity.get("type", "unknown"))
                    entity_name_to_id[entity["name"]] = entity_id
                    logger.debug(f"[Apply Results] å®žä½“æ˜ å°„: '{entity['name']}' -> '{entity_id}'")

            logger.info(f"[Apply Results] å®žä½“åç§°æ˜ å°„å®Œæˆï¼Œå…± {len(entity_name_to_id)} ä¸ªæ˜ å°„")

            # å»ºç«‹å…³ç³»
            for i, rel in enumerate(relationships):
                source_name = rel.get("source")
                target_name = rel.get("target")

                if not source_name or not target_name:
                    logger.warning(f"[Apply Results] å…³ç³»{i+1}ç¼ºå°‘æºæˆ–ç›®æ ‡åç§°ï¼Œè·³è¿‡")
                    continue

                # ä»Žæ˜ å°„ä¸­èŽ·å–æ­£ç¡®çš„å®žä½“ID
                source_id = entity_name_to_id.get(source_name)
                target_id = entity_name_to_id.get(target_name)

                if not source_id or not target_id:
                    logger.warning(f"[Apply Results] å…³ç³»{i+1}æ‰¾ä¸åˆ°å®žä½“ID: source='{source_name}' -> {source_id}, target='{target_name}' -> {target_id}")
                    logger.warning(f"[Apply Results] å¯ç”¨å®žä½“æ˜ å°„: {list(entity_name_to_id.keys())}")
                    continue

                relationship = rel.get("relationship", "related")
                logger.info(f"[Apply Results] æ­£åœ¨æ·»åŠ å…³ç³»{i+1}: {source_name}({source_id}) --{relationship}--> {target_name}({target_id})")

                # ç¡®ä¿æºå’Œç›®æ ‡å®žä½“å­˜åœ¨
                if (self.memory.knowledge_graph.get_node(source_id) and
                    self.memory.knowledge_graph.get_node(target_id)):
                    self.memory.add_edge(source_id, target_id, relationship)
                    edges_added += 1
                    logger.info(f"[Apply Results] å…³ç³»{i+1}æ·»åŠ æˆåŠŸ, å½“å‰ edges_added = {edges_added}")
                else:
                    logger.warning(f"[Apply Results] å…³ç³»{i+1}ä¸­çš„å®žä½“ä¸å­˜åœ¨: {source_id} æˆ– {target_id}")

        except Exception as e:
            logger.error(f"[Apply Results] åº”ç”¨LLMåˆ†æžç»“æžœæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            logger.error(f"[Apply Results] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

        logger.info(f"[Apply Results] åº”ç”¨å®Œæˆ: æœ€ç»ˆç»Ÿè®¡ nodes_added={nodes_added}, edges_added={edges_added}")
        return nodes_added, edges_added
    
    def _generate_entity_id(self, name: str, entity_type: str) -> str:
        """ç”Ÿæˆä¸€è‡´çš„å®žä½“ID"""
        clean_name = name.strip().lower().replace(" ", "_")
        return f"{entity_type}_{clean_name}"
    
    def _fallback_simple_initialization(self, char_name: str, char_description: str) -> Dict[str, Any]:
        """ç®€åŒ–çš„å›žé€€åˆå§‹åŒ–æ–¹æ³•ï¼Œä»…åˆ›å»ºä¸»è§’è‰²å®žä½“"""
        logger.info("ðŸ”„ ä½¿ç”¨ç®€åŒ–æ¨¡å¼åˆå§‹åŒ–è§’è‰²...")
        
        try:
            # åªåˆ›å»ºä¸»è§’è‰²å®žä½“
            character_id = self._generate_entity_id(char_name, "character")
            
            attributes = {
                "name": char_name,
                "description": char_description[:200] if char_description else "ä¸»è¦è§’è‰²",
                "is_main_character": True,
                "source": "simple_fallback"
            }
            
            self.memory.add_or_update_node(character_id, "character", **attributes)
            
            logger.info(f"âœ… ç®€åŒ–åˆå§‹åŒ–å®Œæˆ: 1 ä¸ªä¸»è§’è‰²å®žä½“")
            
            # ä¿å­˜å›¾è°±åˆ°GraphMLæ ¼å¼
            if self.memory.graph_save_path:
                self.memory.knowledge_graph.save_graph(self.memory.graph_save_path)

            # åŒæ­¥å®žä½“æ•°æ®åˆ°JSONæ–‡ä»¶ï¼Œä¾›UIä½¿ç”¨
            self.memory.sync_entities_to_json()
            logger.info("âœ… ç®€åŒ–æ¨¡å¼å®žä½“æ•°æ®å·²åŒæ­¥åˆ° entities.json")

            return {
                "nodes_added": 1,
                "edges_added": 0,
                "method": "simple_fallback",
                "character_name": char_name
            }
            
        except Exception as e:
            logger.error(f"âŒ ç®€åŒ–åˆå§‹åŒ–ä¹Ÿå¤±è´¥äº†: {e}")
            return {
                "nodes_added": 0,
                "edges_added": 0,
                "method": "failed",
                "error": str(e)
            }

    def extract_updates_from_response(self, llm_response: str, user_input: str = "") -> Dict[str, Any]:
        """
        æ™ºèƒ½åˆ†æžå¯¹è¯å†…å®¹ï¼Œç”Ÿæˆç²¾ç¡®çš„çŸ¥è¯†å›¾è°±æ›´æ–°æ“ä½œã€‚
        ä¼˜å…ˆä½¿ç”¨GRAG Agentè¿›è¡Œåˆ†æžï¼Œå›žé€€åˆ°æœ¬åœ°å¤„ç†å™¨ã€‚
        """
        if self.grag_agent:
            logger.info("ä½¿ç”¨GRAGæ™ºèƒ½Agentåˆ†æžå¯¹è¯æ›´æ–°...")
            return self._extract_with_agent(user_input, llm_response)
        else:
            logger.info("ä½¿ç”¨æœ¬åœ°æ–‡æœ¬å¤„ç†å™¨æå–æ›´æ–°...")
            return self._extract_with_local_processor(llm_response)
    
    def _extract_with_agent(self, user_input: str, llm_response: str) -> Dict[str, Any]:
        """ä½¿ç”¨GRAG Agentè¿›è¡Œæ™ºèƒ½åˆ†æž"""
        try:
            # 1. Agentåˆ†æžå¯¹è¯ç”Ÿæˆæ›´æ–°æŒ‡ä»¤
            recent_context = self._get_recent_conversation_context()
            analysis_result = self.grag_agent.analyze_conversation_for_updates(
                user_input=user_input,
                llm_response=llm_response, 
                current_graph=self.memory.knowledge_graph,
                recent_context=recent_context
            )
            
            if "error" in analysis_result:
                logger.warning(f"Agentåˆ†æžå¤±è´¥ï¼Œå›žé€€åˆ°æœ¬åœ°å¤„ç†å™¨: {analysis_result['error']}")
                return self._extract_with_local_processor(llm_response)
            
            # 2. å°†Agentç»“æžœè½¬æ¢ä¸ºæ‰§è¡Œæ ¼å¼
            execution_format = self.grag_agent.convert_to_execution_format(analysis_result)
            
            # 3. éªŒè¯æ›´æ–°
            validated_updates = self.validation_layer.validate(execution_format, self.memory.knowledge_graph)
            
            # 4. åº”ç”¨æ›´æ–°
            return self._apply_validated_updates(validated_updates, source="grag_agent")
            
        except Exception as e:
            logger.error(f"Agentåˆ†æžè¿‡ç¨‹å‡ºé”™: {e}")
            logger.info("å›žé€€åˆ°æœ¬åœ°æ–‡æœ¬å¤„ç†å™¨...")
            return self._extract_with_local_processor(llm_response)
    
    def _extract_with_local_processor(self, llm_response: str) -> Dict[str, Any]:
        """ä½¿ç”¨æœ¬åœ°RPGæ–‡æœ¬å¤„ç†å™¨ï¼ˆå›žé€€æ–¹æ¡ˆï¼‰"""
        try:
            # ä½¿ç”¨RPGæ–‡æœ¬å¤„ç†å™¨æå–å®Œæ•´çš„æ¸¸æˆå…ƒç´ æ›´æ–°
            updates = self.rpg_processor.extract_rpg_entities_and_relations(llm_response)
            
            # éªŒè¯å¹¶åº”ç”¨æ›´æ–°
            validated_updates = self.validation_layer.validate(updates, self.memory.knowledge_graph)

            # åº”ç”¨æ›´æ–°
            return self._apply_validated_updates(validated_updates, source="local_processor")
            
        except Exception as e:
            logger.error(f"æœ¬åœ°å¤„ç†å™¨åˆ†æžå¤±è´¥: {e}")
            # è¿”å›žå®‰å…¨çš„ç©ºç»“æžœ
            return {"nodes_updated": 0, "edges_added": 0, "nodes_deleted": 0, "edges_deleted": 0}
    
    def _apply_validated_updates(self, validated_updates: Dict[str, Any], source: str = "unknown") -> Dict[str, Any]:
        """ç»Ÿä¸€çš„æ›´æ–°åº”ç”¨é€»è¾‘"""
        if not validated_updates:
            logger.info("æ²¡æœ‰æœ‰æ•ˆçš„æ›´æ–°éœ€è¦åº”ç”¨")
            return {"nodes_updated": 0, "edges_added": 0, "nodes_deleted": 0, "edges_deleted": 0}

        nodes_updated_count = len(validated_updates.get("nodes_to_update", []))
        edges_added_count = len(validated_updates.get("edges_to_add", []))
        nodes_deleted_count = 0
        edges_deleted_count = 0

        # å¤„ç†åˆ é™¤äº‹ä»¶ï¼ˆä¼˜å…ˆï¼‰
        deletion_stats = self._process_deletion_events(validated_updates)
        nodes_deleted_count = deletion_stats.get("nodes_deleted", 0)
        edges_deleted_count = deletion_stats.get("edges_deleted", 0)

        # åº”ç”¨èŠ‚ç‚¹æ›´æ–°
        for node_update in validated_updates.get("nodes_to_update", []):
            try:
                # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æžœä¸å­˜åœ¨åˆ™åˆ›å»º
                if not self.memory.knowledge_graph.graph.has_node(node_update['node_id']):
                    # å°è¯•ä»Žå±žæ€§ä¸­æŽ¨æ–­ç±»åž‹
                    node_type = node_update.get('type', 'unknown')
                    if node_type == 'unknown' and "location" in node_update.get('attributes', {}):
                        node_type = "character" # æœ‰ä½ç½®çš„é€šå¸¸æ˜¯è§’è‰²
                    
                    self.memory.add_or_update_node(
                        node_update['node_id'], 
                        node_type, 
                        **node_update['attributes']
                    )
                else:
                    # èŠ‚ç‚¹å­˜åœ¨ï¼Œåªæ›´æ–°å±žæ€§
                    existing_node = self.memory.knowledge_graph.get_node(node_update['node_id'])
                    node_type = existing_node.get('type', 'unknown')
                    self.memory.add_or_update_node(
                        node_update['node_id'], 
                        node_type, 
                        **node_update['attributes']
                    )
            except Exception as e:
                logger.warning(f"Failed to update node {node_update['node_id']}: {e}")
                nodes_updated_count -= 1
        
        # åº”ç”¨è¾¹æ›´æ–°
        for edge_add in validated_updates.get("edges_to_add", []):
            try:
                self.memory.add_edge(
                    edge_add['source'], 
                    edge_add['target'], 
                    edge_add['relationship']
                )
            except Exception as e:
                logger.warning(f"Failed to add edge {edge_add['source']} -> {edge_add['target']}: {e}")
                edges_added_count -= 1
        
        logger.info(f"æˆåŠŸåº”ç”¨æ›´æ–°({source}): {nodes_updated_count} nodes updated, {edges_added_count} edges added, {nodes_deleted_count} nodes deleted, {edges_deleted_count} edges deleted.")
        
        # ä¿å­˜çŸ¥è¯†å›¾è°±åˆ°GraphMLæ ¼å¼
        if self.memory.graph_save_path:
            self.memory.knowledge_graph.save_graph(self.memory.graph_save_path)

        # åŒæ­¥å®žä½“æ•°æ®åˆ°JSONæ–‡ä»¶ï¼Œä¾›UIä½¿ç”¨
        self.memory.sync_entities_to_json()
        logger.info("âœ… å®žä½“æ•°æ®å·²åŒæ­¥åˆ° entities.json")

        return {
            "nodes_updated": nodes_updated_count,
            "edges_added": edges_added_count,
            "nodes_deleted": nodes_deleted_count,
            "edges_deleted": edges_deleted_count
        }
    
    def _get_recent_conversation_context(self) -> str:
        """èŽ·å–æœ€è¿‘çš„å¯¹è¯ä¸Šä¸‹æ–‡ç”¨äºŽAgentåˆ†æž"""
        try:
            recent_history = self.memory.basic_memory.conversation_history[-3:]  # æœ€è¿‘3è½®å¯¹è¯
            context_parts = []
            
            for turn in recent_history:
                user_msg = turn.get("user", "")
                assistant_msg = turn.get("assistant", "")
                if user_msg:
                    context_parts.append(f"ç”¨æˆ·: {user_msg}")
                if assistant_msg:
                    context_parts.append(f"åŠ©æ‰‹: {assistant_msg}")
            
            return "\n".join(context_parts) if context_parts else ""
        except:
            return ""

    def _process_deletion_events(self, validated_updates: Dict[str, Any]) -> Dict[str, int]:
        """
        å¤„ç†åˆ é™¤äº‹ä»¶ï¼ŒåŒ…æ‹¬èŠ‚ç‚¹åˆ é™¤å’Œè¾¹åˆ é™¤
        
        Args:
            validated_updates: éªŒè¯åŽçš„æ›´æ–°æ•°æ®
            
        Returns:
            Dict: åˆ é™¤ç»Ÿè®¡ä¿¡æ¯
        """
        nodes_deleted = 0
        edges_deleted = 0
        
        # å¤„ç†èŠ‚ç‚¹åˆ é™¤
        for node_deletion in validated_updates.get("nodes_to_delete", []):
            try:
                node_id = node_deletion["node_id"]
                deletion_type = node_deletion.get("deletion_type", "default")
                reason = node_deletion.get("reason", "No reason provided")
                
                if deletion_type == "death":
                    # è§’è‰²æ­»äº¡ä½¿ç”¨è½¯åˆ é™¤
                    self.memory.mark_node_as_deleted(node_id, reason)
                    logger.info(f"Character marked as dead: {node_id} - {reason}")
                elif deletion_type == "lost":
                    # ç‰©å“ä¸¢å¤±ä½¿ç”¨ç¡¬åˆ é™¤
                    if self.memory.delete_node(node_id):
                        logger.info(f"Item permanently deleted: {node_id} - {reason}")
                    else:
                        logger.warning(f"Failed to delete node {node_id}: node not found")
                        continue
                else:
                    # é»˜è®¤è½¯åˆ é™¤
                    self.memory.mark_node_as_deleted(node_id, reason)
                    logger.info(f"Node marked as deleted: {node_id} - {reason}")
                
                nodes_deleted += 1
                
            except Exception as e:
                logger.warning(f"Failed to process node deletion {node_deletion.get('node_id', 'unknown')}: {e}")
        
        # å¤„ç†è¾¹åˆ é™¤
        for edge_deletion in validated_updates.get("edges_to_delete", []):
            try:
                source = edge_deletion.get("source")
                target = edge_deletion.get("target") 
                relationship = edge_deletion.get("relationship")
                reason = edge_deletion.get("reason", "No reason provided")
                
                # æ”¯æŒé€šé…ç¬¦åˆ é™¤
                if source == "*" or relationship == "*":
                    # æ‰¾åˆ°æ‰€æœ‰åŒ¹é…çš„è¾¹å¹¶åˆ é™¤
                    graph = self.memory.knowledge_graph.graph
                    edges_to_remove = []
                    
                    for src, tgt, edge_data in graph.edges(data=True):
                        match = True
                        if source != "*" and src != source:
                            match = False
                        if target != "*" and tgt != target:
                            match = False
                        if relationship != "*" and edge_data.get("relationship") != relationship:
                            match = False
                        
                        if match:
                            edges_to_remove.append((src, tgt, edge_data.get("relationship")))
                    
                    for src, tgt, rel in edges_to_remove:
                        if self.memory.delete_edge(src, tgt, rel):
                            edges_deleted += 1
                            logger.info(f"Edge deleted: {src} --{rel}--> {tgt} - {reason}")
                else:
                    # ç²¾ç¡®åˆ é™¤
                    if self.memory.delete_edge(source, target, relationship):
                        edges_deleted += 1
                        logger.info(f"Edge deleted: {source} --{relationship}--> {target} - {reason}")
                    else:
                        logger.warning(f"Failed to delete edge {source} -> {target}: edge not found")
                        
            except Exception as e:
                logger.warning(f"Failed to process edge deletion: {e}")
        
        return {
            "nodes_deleted": nodes_deleted,
            "edges_deleted": edges_deleted
        }
